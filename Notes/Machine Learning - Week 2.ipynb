{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Machine Learning - Week 2</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Multiple Linear Regression</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Notation\n",
    "\n",
    "**Multiple Linear Regression:** Use more than one feature to estimate the dependent variable\n",
    " - $n$ = number of features, $m$ = number of training examples\n",
    " - $x^{(i)}$ = features of the $i^{th}$ training example (vector)\n",
    " - $x_j$ = input feature $j$\n",
    " - $x_j^{(i)}$ = value of feature $j$ in the $i^{th}$ training example\n",
    " \n",
    " \n",
    " **Hypothesis Function:** $h_\\theta(x) = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + \\ldots + \\theta_nx_n \\space \\space \\leftrightarrow \\space \\space h_\\theta(x) = \\theta_0x_0 + \\theta_1x_1 + \\ldots + \\theta_nx_n$\n",
    "  - Define $x_0 = 1 \\space \\leftrightarrow \\space x_0^{(i)} = 1$ for all training examples $i$\n",
    "  - $n+1$ dimensional feature vector $x$ and $n+1$ dimensional parameter vector $\\theta$ (0-indexed)\n",
    "  \n",
    "  $x = \\begin{bmatrix} x_0 \\\\ x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix} \\in \\mathbb{R}^{n+1} \\space \\space \\space \\space \\theta = \\begin{bmatrix} \\theta_0 \\\\ \\theta_1 \\\\ \\theta_2 \\\\ \\vdots \\\\ \\theta_n \\end{bmatrix} \\in \\mathbb{R}^{n+1}$\n",
    "  - Can be written as: $\\theta^Tx = \\begin{bmatrix} \\theta_0 \\space \\space \\space \\theta_1 \\space \\space \\space \\dots \\space \\space \\space \\theta_n \\end{bmatrix} \\cdot \\begin{bmatrix} x_0 \\\\ x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent with Multiple Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cost Function:** $J(\\theta_0,\\theta_1,\\ldots,\\theta_n) = J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)})^2$\n",
    "\n",
    "**Gradient Descent Algorithm:**\n",
    "\n",
    "$\\text{repeat } \\{$\n",
    "\n",
    "&emsp;$ \\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j}J(\\theta) \\space \\space \\leftrightarrow \\space \\space \\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_j^{(i)}$\n",
    "\n",
    "$\\} \\space (\\text{simultaneously update for every } j = 0,\\ldots,n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Gradient Descent in Practice</center></h2>\n",
    "\n",
    "### Feature Scaling\n",
    "\n",
    "**Feature Scaling:** Make sure features are on a similar scale $\\rightarrow$ $x_i := \\frac{x_i}{s_i}$ where $s_i$ is the range (max - min)\n",
    " - If variables are of vastly different magnitude, the contour graph will be quite skewed, therefore gradient descent will take long to reach a minimum\n",
    " - Scale features into aprrox. a $-1 \\leq x_i \\leq 1$ range $\\rightarrow$ does not need to be the same for each feature, but should be within:\n",
    "     - Max of $\\pm 3$ \n",
    "     - Min of $\\pm \\frac{1}{3}$\n",
    "\n",
    "\n",
    "**Mean Normalization:** $x_i := \\frac{x_i-\\mu_i}{s_i}$ where $s_i$ is the range (max - min) or standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing $\\alpha$ Value\n",
    "\n",
    "![](img/check-gd-working.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot cost as a function of the number of iterations, and check if decreasing with each iteration $\\rightarrow$ can check convergence visually\n",
    " - Algorithm to check convergence: Declare convergence if $J(\\theta)$ decreases by less than some small value $\\epsilon$ in one iteration (for example $10^{-3}$)\n",
    " - If $J(\\theta)$ increases with iterations, or alternates between increasing and decreasing, gradient descent isn't working $\\rightarrow$ use a smaller $\\alpha$\n",
    " - To choose $\\alpha$, try $\\ldots, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, \\ldots$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features can be calculated; for example, given $x_1 = \\text{length}$ and $x_2 = \\text{width}$ we might simply use $x = \\text{area}$ to predict instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Polynomial Regression:** Fit a polynomial instead of a straight line: $h_\\theta(x) = \\theta_0 + \\theta_1x + \\theta_2x^2 \\leftrightarrow \\theta_0 + \\theta_1x_1 + \\theta_2x_2$ where $x_1 = x$ and $x_2 = x^2$\n",
    "- Exponents can be fractional (square roots) as well\n",
    "- Feature scaling may be important when dealing with higher order polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Normal Equation</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normal Equation:** Method of solving gradient descent analytically instead of iteratively\n",
    "- Intuition: For every $j$, solve for $\\theta_j$ by equating $\\frac{\\partial}{\\partial\\theta_j}J(\\theta) = 0$\n",
    "- Feature scaling unnecessary for normal equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Design Matrix $X$:** A matrix containing all our input data used to computer the optimal value of $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For every set of training examples $x^{(i)}$, $(x^{(i)})^T$ becomes a row in the design matrix:\n",
    "\n",
    "$x^{(i)} = \\begin{bmatrix} x_0^{(i)} \\\\ x_1^{(i)} \\\\ x_2^{(i)} \\\\ \\vdots \\\\ x_n^{(i)} \\end{bmatrix} \\in \\mathbb{R}^{n+1} \\rightarrow X = \\begin{bmatrix} (x^{(1)})^T \\\\ (x^{(2)})^T \\\\ \\vdots \\\\ (x^{(m)})^T \\end{bmatrix} = \\begin{bmatrix} x_0^{(1)} & x_1^{(1)} & x_2^{(1)} & \\dots & x_n^{(1)} \\\\ x_0^{(2)} & x_1^{(2)} & x_2^{(2)} & \\dots & x_n^{(2)} \\\\ \\vdots \\\\ x_0^{(m)} & x_1^{(m)} & x_2^{(m)} & \\dots & x_n^{(m)}\\end{bmatrix}$\n",
    "\n",
    "- We also need the $y$ vector:\n",
    "\n",
    "$y = \\begin{bmatrix} y^{(1)} \\\\ y^{(2)} \\\\ \\vdots \\\\y^{(m)}\\end{bmatrix}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve for $\\theta$ we use:\n",
    "$\\theta = (X^TX)^{-1}X^Ty$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to use Gradient Descent vs. Normal Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages of Gradient Descent:**\n",
    "- Runtime $O(kn^2)$ where $k$ is number of iterations $\\rightarrow$ compare to normal equation runtime of $O(n^3)$ due to calculating the inverse of an $n \\times n$ matrix ($X^TX)$\n",
    "- Works well when $n$ is large\n",
    "\n",
    "**Advantages of Normal Equation:**\n",
    "- No need to choose $\\alpha$\n",
    "- No need to iterate\n",
    "\n",
    "\n",
    "Consider normal equation when $n \\geq 10000$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues with Noninvertibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Noninvertibility:** The matrix $X^TX$ cannot be inverted\n",
    "- Solution: use `pinv` function\n",
    "- Two primary causes\n",
    "    1. Redundant features (linearly dependent): $x_1 = cx_2$\n",
    "    2. Too many features ($m \\leq n$): Delete features or use regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Vectorization</center></h2>\n",
    "\n",
    "**Vectorization:** Using matrix algebra to compute gradient descent, as opposed to using `for` loops\n",
    "\n",
    "#### Hypothesis\n",
    "\n",
    "$h_\\theta(x) = \\theta_0x_0 + \\theta_1x_1 + \\ldots + \\theta_jx_j = \n",
    "\\begin{bmatrix}x_0^{(1)} & x_1^{(1)} & \\dots & x_j^{(1)} \\\\\n",
    "x_0^{(2)} & x_1^{(2)} & \\dots & x_j^{(2)} \\\\\n",
    "\\vdots \\\\\n",
    "x_0^{(m)} & x_1^{(m)} & \\dots & x_j^{(m)}\n",
    "\\end{bmatrix} \\cdot \\begin{bmatrix} \\theta_0 \\\\ \\theta_1 \\\\ \\vdots \\\\ \\theta_j \\end{bmatrix} = \n",
    "X\\theta$\n",
    "\n",
    "#### Cost Function\n",
    "\n",
    "$J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)})^2 = \\frac{1}{2m}(X\\theta-y)^T(X\\theta-y)$\n",
    "\n",
    "#### Sum of Derivatives of Cost Function\n",
    "\n",
    "$\\frac{\\partial J(\\theta)}{\\partial \\theta} = \\frac{1}{m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_j^{(i)} = \\frac{1}{m}X^T(X\\theta-y)$\n",
    "\n",
    "#### Gradient Descent\n",
    "For each iteration: $\\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_j^{(i)} \\leftrightarrow \\\\ \\theta := \\theta - \\alpha \\frac{1}{m}X^T(X\\theta-y)$\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/vectorization-implementation-in-machine-learning-ca652920c55d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
