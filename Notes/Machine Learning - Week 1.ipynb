{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Machine Learning?\n",
    "\n",
    "**Machine Learning:**\n",
    " - Computers learn w/o being programmed\n",
    " - Computers learn from experience $E$ w/ respect to task $T$ if performance, as measured by $P$ improves w/ experience $E$\n",
    " \n",
    "**Supervised Learning:** Algorithm is taught (fed correct data)\n",
    " - *Regression:* Predict a continuous valued ouptut\n",
    " - *Classification:* Predict a discrete valued output\n",
    "\n",
    "**Unsupervised Learning:** Algorithm learns by itself (no correct data)\n",
    " - *Clustering:* Automatically group data into clusters\n",
    "\n",
    "Others: **reinforcement learning**, **recommender systems**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Representation\n",
    "\n",
    "$m$ - Number of training examples, $x$ - Input variables, $y$ - Output variables\n",
    "\n",
    "$(x,y)$ - One training example, $(x_i,y_i)$ - $i$th training example\n",
    "\n",
    "Training Set $\\rightarrow$ Learning Algorithm $\\rightarrow$ $h$\n",
    "\n",
    "**Hypothesis:**\n",
    " - $h$ maps $x$'s to $y$'s\n",
    " - $h_{\\theta}(x) = \\theta_0 + \\theta_1x$ in Univariate Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression:** Fit a line through the data and use to predict\n",
    " - *Univariate/Simple:* One input variable\n",
    " - *Multivariate/Multiple:* More than one input variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost\n",
    "\n",
    "**Cost Function:** A measure of how well the line fits\n",
    "\n",
    "**MSE (Mean Squared Error):** A measure of the average difference between predicted and actual values: $J(\\theta_1,\\theta_2) = {\\frac{1}{2m}} {\\sum_{i=1}^m {(h_{\\theta}(x_i) - y_i)^2}}$\n",
    " - We square to get rid of negatives\n",
    " - We divide average by 2 to make gradient descent differentiation easier\n",
    " - MSE can be visualized as a function of $\\theta_0, \\theta_1$ using contour plots (2D depictions of 3D plots)\n",
    " - Goal of linear regression is to $\\min_{\\theta_0,\\theta_1}J(\\theta_1,\\theta_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "\n",
    "**Gradient Descent Algorithm:** Used to find minimums on functions: Start with some $\\theta_0, \\theta_1$ $\\rightarrow$ Change $\\theta_0, \\theta_1$ until minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
